{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.window import Window,WindowSpec\nimport numpy as np\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["spark = SparkSession.builder.appName('temp').getOrCreate()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["df = spark.read.format('csv').load('/FileStore/tables/Machine_learning/data_science_screening_exercise_orders.csv', inferschema = True, header = True)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#df.show()\n#df.describe().show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["ordered_data = df.orderBy('customer_id')\nranked_data = ordered_data.withColumn(\"rank\",rank().over(Window.partitionBy(\"customer_id\").orderBy((\"date\"))))\nranked_data.show()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["grouped = ranked_data.groupBy(\"customer_id\").agg(collect_list(struct(\"date\", \"rank\")).alias(\"tmp\"))\ngrouped_data = grouped.select(\"customer_id\", sort_array(\"tmp\")[\"rank\"].alias(\"customer_ranks\"))\ngrouped_data.show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["grouped_data = grouped.select(\"customer_id\", sort_array(\"tmp\")[\"rank\"].alias(\"customer_ranks\"))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["result = (grouped_data.drop('customer_id'))\nresult.show()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["result1 = result.collect()\nresult1"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"test2","notebookId":2710202829078378},"nbformat":4,"nbformat_minor":0}
