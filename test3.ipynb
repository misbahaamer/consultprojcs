{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.window import Window,WindowSpec\nfrom pyspark.sql.types import *\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["spark = SparkSession.builder.appName('temp').getOrCreate()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["df = spark.read.format('csv').load('/FileStore/tables/Machine_learning/data_science_screening_exercise_orders.csv', inferschema = True, header = True)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["data = df.withColumn('week', date_format(to_date(\"date\", \"dd/MMM/yyyy\"), \"W\"))\n#data.show()\ndisplay(data)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["d1[45][0]"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["d2 = pd.DataFrame({'week':week})\n#d2\nd3 = sqlContext.createDataFrame(d2)\ndisplay(d3)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["ordered_data = df.orderBy('customer_id')\ncount_data = ordered_data.groupBy('customer_id').count()\ncount_data.show()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["ranked_data = ordered_data.withColumn(\"rank\",rank().over(Window.partitionBy(\"customer_id\").orderBy((\"date\"))))\nranked_data.show()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["recent_orders = ranked_data.filter(\"rank==1\")\nrecent_orders.show()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#data = recent_orders.join(count_data,recent_orders.customer_id == count_data.customer_id)\ndata = recent_orders.join(count_data,on = 'customer_id')\n#data1 = data.withColumnRenamed('count', 'order_count').show()\n#data2 = data.drop('value','rank').show()\n#data2.show()\ndata.show()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#data1 = data.withColumnRenamed('count', 'order_count')\ndata2 = data1.drop('value','rank')\ndata2.show()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["grouped_data = data2.withColumn('day', dayofmonth('date'))\ndisplay(grouped_data)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["#final_data = grouped_data.withColumn(\"WEEK\", when(grouped_data[\"week\"] == 52,1).otherwise(grouped_data[\"week\"]))\n#final_data.withColumn(\"WEEK\",\n  #when(col(\"week\")==52, 1).otherwise(\"week\"))\n#final_data.printSchema().show()\nfinal1 = final_data.select(final_data.customer_id,\n                            final_data.gender,\n                            final_data.date,\n                            final_data.order_count.cast(\"integer\"),\n                            final_data.WEEK.cast(\"integer\")\n                             )\nfinal1.printSchema()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["final_data.groupBy('order_count').count().show()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["display(final1)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#final2 = final1.select('gender', 'order_count', 'WEEK')\n#x = final2.select('WEEK').collect()\nweek_list = final2.select(\"WEEK\").rdd.flatMap(lambda x: x).collect()\norder_count_list = final2.select(\"order_count\").rdd.flatMap(lambda x: x).collect()\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["data_schema =[StructField(\"Week_list\", IntegerType() , True),\n         StructField(\"order_count\", IntegerType(), True)]\nfinal_struct = StructType(fields=data_schema)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#ids = [x for x in range(len(week_list))]\ns1 = pd.Series(week_list, name = 'week')\ns2 = pd.Series(order_count_list, name='weekly_orders')\ns3 = pd.concat([s1,s2], axis =1)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["df = spark.read.format('csv').load('/FileStore/tables/Machine_learning/final.csv', inferschema = True, header = True)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["df1 = df.orderBy('WEEK').select('WEEK', 'gender' , 'order_count')\n\ndisplay(df1)\n"],"metadata":{},"outputs":[],"execution_count":21}],"metadata":{"name":"test3","notebookId":3419434651179152},"nbformat":4,"nbformat_minor":0}
